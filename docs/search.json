[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistics for babies",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "lm.html",
    "href": "lm.html",
    "title": "1  Linear models",
    "section": "",
    "text": "Design matrix \\(X\\)\nEach row represents an individual object, columns corresponding to the variables and their specific values for that object\nA regression model may be represented via matrix multiplication as\n\\[y = X \\beta + \\varepsilon\\]\nThe simple linear regression model\n\\[y_i = \\underbrace{\\beta_0 + \\beta_1 x_i}_{X \\beta} + \\varepsilon_i\\]\nThis model can be represented in matrix form as\n\\[\n\\underbrace{\\left[\\begin{array}{l}\ny_1 \\\\\ny_2 \\\\\ny_3\n\\end{array}\\right]}_{y}\n=\n\\underbrace{\\left[\\begin{array}{ll}\n1 & x_1 \\\\\n1 & x_2 \\\\\n1 & x_3\n\\end{array}\\right]}_{X}\n\\underbrace{\\left[\\begin{array}{l}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\vphantom{}\n\\end{array}\\right]}_{\\beta}\n+\n\\underbrace{\\left[\\begin{array}{l}\n\\varepsilon_1 \\\\\n\\varepsilon_2 \\\\\n\\varepsilon_3\n\\end{array}\\right]}_{\\epsilon}\n\\]\n\nlibrary(tidyverse)\n\ndf &lt;- read.csv(\"data/classroom.csv\")\n\nUse a linear model to estimate a global intercept for mathgain, which is equal to the mean of the variable\n\nlm(mathgain ~ 1, data = df)\n\n\nCall:\nlm(formula = mathgain ~ 1, data = df)\n\nCoefficients:\n(Intercept)  \n      57.57  \n\nmean(df$mathgain)\n\n[1] 57.56639\n\n\nLet look at a subset of the data from schoolid == 3\n\ntmp &lt;- df |&gt; \n  filter(schoolid == 3) |&gt; \n  mutate(\n    classid = factor(classid)\n  )\n\n\nlm(mathgain ~ classid, data = tmp)\n\n\nCall:\nlm(formula = mathgain ~ classid, data = tmp)\n\nCoefficients:\n(Intercept)   classid137   classid145   classid228  \n       85.0         20.5         11.0        -14.0  \n\n\n\ntmp |&gt; \n  group_by(classid) |&gt; \n  summarise(mean_mathgain = mean(mathgain))\n\n\n  \n\n\n\nSo you can see the intercept (85.0) is the mean of classid == 11. The mean of classid == 137 is 105.5, which is 85 + 20.5 (intercept + slope) from the linear model. And so on, mean of classid == 145 is 96 which is classid == 11 + 11 (85+11).\nIf you want an intercept for each class, put - 1 in the lm formula\n\nlm(mathgain ~ classid - 1, data = tmp)\n\n\nCall:\nlm(formula = mathgain ~ classid - 1, data = tmp)\n\nCoefficients:\n classid11  classid137  classid145  classid228  \n      85.0       105.5        96.0        71.0  \n\n\nBy default, reference group is the first group in a factor\n\nlm(mathgain ~ classid + mathkind - 1, data = tmp)\n\n\nCall:\nlm(formula = mathgain ~ classid + mathkind - 1, data = tmp)\n\nCoefficients:\n classid11  classid137  classid145  classid228    mathkind  \n  404.1494    431.5223    435.9090    404.8938     -0.7049  \n\n\n\nlm(mathgain ~ classid * mathkind - 1, data = tmp)\n\n\nCall:\nlm(formula = mathgain ~ classid * mathkind - 1, data = tmp)\n\nCoefficients:\n          classid11           classid137           classid145  \n           187.7939             596.0303             561.1480  \n         classid228             mathkind  classid137:mathkind  \n          1376.9393              -0.2270              -0.8336  \nclassid145:mathkind  classid228:mathkind  \n            -0.7376              -2.5300",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Linear models</span>"
    ]
  },
  {
    "objectID": "lmer.html",
    "href": "lmer.html",
    "title": "2  Mixed-effects model",
    "section": "",
    "text": "2.1 Notation\nLinear mixed models (LMMs) are statistical models that incorporate fixed and random effects to accurately represent non-independent data structures. LMM is an alternative to analysis of variance.\nModels with both fixed and random-effects are called mixed-effect models.\n\\[y = X\\beta + Zu + \\varepsilon\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Mixed-effects model</span>"
    ]
  },
  {
    "objectID": "lmer.html#notation",
    "href": "lmer.html#notation",
    "title": "2  Mixed-effects model",
    "section": "",
    "text": "\\(y\\) is a vector of observations\n\\(X\\) is the design matrix for the fixed effects\n\\(\\beta\\) is a vector of fixed-effect parameters\n\\(Z\\) is the design matrix for the random effects\n\\(u\\) is a vector of random-effect parameters\n\\(\\varepsilon\\) is a vector of random errors",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Mixed-effects model</span>"
    ]
  },
  {
    "objectID": "lmer.html#a-simple-example",
    "href": "lmer.html#a-simple-example",
    "title": "2  Mixed-effects model",
    "section": "2.2 A simple example",
    "text": "2.2 A simple example\nWe want to predict test score \\(y\\) from hours studied \\(x\\) in 2 classrooms \\(i \\in \\{1,2\\}\\), each classroom has 3 students \\(j \\in \\{1,2,3\\}\\).\n\n2.2.1 Random intercept\n\\[y = X\\beta + Zu + \\varepsilon\\]\n\\[\n\\left[\\begin{array}{ll}\ny_{11} \\\\\ny_{12} \\\\\ny_{13} \\\\\ny_{21} \\\\\ny_{22} \\\\\ny_{23}\n\\end{array}\\right]=\\left[\\begin{array}{ll}\n1 & x_{11} \\\\\n1 & x_{12} \\\\\n1 & x_{13} \\\\\n1 & x_{21} \\\\\n1 & x_{22} \\\\\n1 & x_{23}\n\\end{array}\\right] \\left[\\begin{array}{l}\n\\beta_0 \\\\\n\\beta_1\n\\end{array}\\right] +\n\\left[\\begin{array}{ll}\n1 & 0 \\\\\n1 & 0 \\\\\n1 & 0 \\\\\n0 & 1 \\\\\n0 & 1 \\\\\n0 & 1\n\\end{array}\\right] \\left[\\begin{array}{l}\nb_{0_1} \\\\\nb_{0_2}\n\\end{array}\\right] + \\varepsilon\n\\]\n\\[\\begin{align}\ny_{ij} &= \\beta_0 + \\beta_1 x_{ij} + b_{0_i} + \\varepsilon \\\\\n&= \\underbrace{\\beta_0 + b_{0_i}}_\\text{intercept} + \\underbrace{\\beta_1}_\\text{slope} x_{ij} + \\varepsilon\n\\end{align}\\]\n\nThe intercept for classroom 1 is \\(\\beta_0 + b_{0_1}\\)\nThe intercept for classroom 2 is \\(\\beta_0 + b_{0_2}\\)\nThe slope is \\(\\beta_1\\)\n\n\n\n2.2.2 Random slope\n\\[y = X\\beta + Zu + \\varepsilon\\]\n\\[\n\\left[\\begin{array}{ll}\ny_{11} \\\\\ny_{12} \\\\\ny_{13} \\\\\ny_{21} \\\\\ny_{22} \\\\\ny_{23}\n\\end{array}\\right]=\\left[\\begin{array}{ll}\n1 & x_{11} \\\\\n1 & x_{12} \\\\\n1 & x_{13} \\\\\n1 & x_{21} \\\\\n1 & x_{22} \\\\\n1 & x_{23}\n\\end{array}\\right] \\left[\\begin{array}{l}\n\\beta_0 \\\\\n\\beta_1\n\\end{array}\\right] +\n\\left[\\begin{array}{ll}\nx_{11} & 0 \\\\\nx_{12} & 0 \\\\\nx_{13} & 0 \\\\\n0 & x_{21} \\\\\n0 & x_{22} \\\\\n0 & x_{23}\n\\end{array}\\right] \\left[\\begin{array}{l}\nb_{1_1} \\\\\nb_{1_2}\n\\end{array}\\right] + \\varepsilon\n\\]\n\\[\\begin{align}\ny_{ij} &= \\beta_0 + \\beta_1 x_{ij} + b_{1_i} x_{ij} + \\varepsilon \\\\\n&= \\underbrace{\\beta_0}_\\text{intercept} + \\underbrace{(\\beta_1 + b_{1_i})}_\\text{slope} x_{ij} + \\varepsilon\n\\end{align}\\]\n\n\n2.2.3 Random intercept and random slope\n\\[y = X\\beta + Zu + \\varepsilon\\]\n\\[\n\\left[\\begin{array}{ll}\ny_{11} \\\\\ny_{12} \\\\\ny_{13} \\\\\ny_{21} \\\\\ny_{22} \\\\\ny_{23}\n\\end{array}\\right]=\\left[\\begin{array}{ll}\n1 & x_{11} \\\\\n1 & x_{12} \\\\\n1 & x_{13} \\\\\n1 & x_{21} \\\\\n1 & x_{22} \\\\\n1 & x_{23}\n\\end{array}\\right] \\left[\\begin{array}{l}\n\\beta_0 \\\\\n\\beta_1\n\\end{array}\\right] +\n\\left[\\begin{array}{ll}\n1 & x_{11} & 0 & 0 \\\\\n1 & x_{12} & 0 & 0 \\\\\n1 & x_{13} & 0 & 0 \\\\\n0 & 0 & 1 & x_{21} \\\\\n0 & 0 & 1 & x_{22} \\\\\n0 & 0 & 1 & x_{23}\n\\end{array}\\right] \\left[\\begin{array}{l}\nb_{0_1} \\\\\nb_{1_1} \\\\\nb_{0_2} \\\\\nb_{1_2}\n\\end{array}\\right] + \\varepsilon\n\\]\n\\[\\begin{align}\ny_{ij} &= \\beta_0 + \\beta_1 x_{ij} + b_{0_i} + b_{1_i} x_{ij} + \\varepsilon \\\\\n&= \\underbrace{\\beta_0 + b_{0_i}}_\\text{intercept} + \\underbrace{(\\beta_1 + b_{1_i})}_\\text{slope} x_{ij} + \\varepsilon\n\\end{align}\\]\n\ndf &lt;- read.csv(\"data/classroom.csv\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Mixed-effects model</span>"
    ]
  },
  {
    "objectID": "lmer.html#random-effects",
    "href": "lmer.html#random-effects",
    "title": "2  Mixed-effects model",
    "section": "2.3 Random effects",
    "text": "2.3 Random effects\n\\[y \\sim \\beta_i x + \\varepsilon\\]\n\\[\\beta_i \\sim \\text{Normal}(\\mu, \\sigma)\\]\nRandom effect assumes that \\(\\beta_i\\) is drawn from \\(\\text{Normal}(\\mu, \\sigma)\\).\n\n# Random intercept\nlmer(y ~ x + (1 | random_group), data = my_data)\n\n# Random slope\nlmer(y ~ x + (random_slope | random_group), data = my_data)\n\nRandom-effect explains more variability than the fixed-effect WHY???\nslopes are being estimated for each classroom, but include a shared distribution. This shared distribution pools information from all classrooms",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Mixed-effects model</span>"
    ]
  },
  {
    "objectID": "inflx.html",
    "href": "inflx.html",
    "title": "3  Inflection point",
    "section": "",
    "text": "3.1 Inflection and turning point\nPapers mentioning “inflection point” often mean one of 4 different things:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inflection point</span>"
    ]
  },
  {
    "objectID": "inflx.html#inflection-and-turning-point",
    "href": "inflx.html#inflection-and-turning-point",
    "title": "3  Inflection point",
    "section": "",
    "text": "3.1.1 Inflection point\n\nWhat it is: Where a smooth curve switches concavity from concave to convex or vice-versa (2nd derivative = 0)\nWhen to use it: When you care about the transition from accelerating to decelerating change\nInterpretation: At \\(x = x_0\\) the curve stops speeding up and starts slowing down.\n\n\n\n3.1.2 Turning point\n\nWhat it is: A local maximum or minimum, where slope changes from increasing to decreasing or vice-versa (1st derivative = 0)\nWhen to use it: For non-monotonic curves, when you want to identify where the effect reaches a peak or a valley. The 1st derivative test tells you if it’s a max or min\nInterpretation: At \\(x = x_0\\), the effect reaches a peak (or valley)\n\nLet use \\(y = x^3 - 6x^2 + 9x\\) as an example:\n\nFirst derivative: \\(y' = 3x^2 - 12x + 9 = 3(x - 1)(x - 3) \\Rightarrow\\) there are 2 turning points:\n\n\\(x = 1, y = 4\\)\n\\(x = 3, y = 0\\)\n\nSecond derivative: \\(y'' = 6x - 12 = 6(x - 2) \\Rightarrow\\) inflection at \\(x = 2, y = 2\\)\n\n\n## Define the function\ny_fun &lt;- function(x) x^3 - 6 * x^2 + 9 * x\n\n# Exact, analytic points\nturn_df &lt;- tibble(\n  name = c(\"Turning (max)\", \"Turning (min)\"),\n  x = c(1, 3),\n  y = y_fun(x)\n)\ninfl_df &lt;- tibble(name = \"Inflection\", x = 2, y = y_fun(x))\n\n# Curve to plot\ndf &lt;- tibble(x = seq(-0.5, 4, length.out = 400)) |&gt;\n  mutate(y = y_fun(x))\n\n# Full-height background bands for concavity\nymin  &lt;- -5\nymax  &lt;- 7.5\nshades &lt;- tibble(\n  xmin = c(-Inf, 2),\n  xmax = c(2, Inf),\n  ymin = ymin,\n  ymax = ymax,\n  curvature = c(\"Concave (y'' &lt; 0)\", \"Convex (y'' &gt; 0)\")\n)\n\n# Plot\nggplot(df, aes(x, y)) +\n  geom_rect(\n    data = shades,\n    aes(\n      xmin = xmin,\n      xmax = xmax,\n      ymin = ymin,\n      ymax = ymax,\n      fill = curvature\n    ),\n    alpha = 0.18,\n    inherit.aes = FALSE\n  ) +\n  geom_line(linewidth = 1) +\n  ## Turning points\n  geom_vline(data = turn_df, aes(xintercept = x), linetype = \"dashed\") +\n  geom_point(data = turn_df,\n             aes(x, y),\n             colour = \"red\",\n             size = 3) +\n  geom_label(\n    data = turn_df,\n    aes(x, y, label = paste0(name, \"\\nx = \", x, \", y = \", y)),\n    fill = \"white\",\n    label.size = 0.2,\n    nudge_y = 2,\n    alpha = 0.5\n  ) +\n  ## Inflection point\n  geom_vline(data = infl_df, aes(xintercept = x), linetype = \"dotted\") +\n  geom_point(data = infl_df,\n             aes(x, y),\n             colour = \"blue\",\n             size = 3) +\n  geom_label(\n    data = infl_df,\n    aes(x, y, label = paste0(name, \"\\nx = \", x, \", y = \", y)),\n    fill = \"white\",\n    label.size = 0.2,\n    nudge_y = -2,\n    alpha = 0.5\n  ) +\n  coord_cartesian(ylim = c(ymin, ymax), expand = 0) +\n  scale_fill_bmj() +\n  labs(fill = \"Curvature\") +\n  theme_classic() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\nWrite functions to find inflection and turning points\n# ---- finite differences that work with uneven x ----\n.fd &lt;- function(x, y) {\n  stopifnot(length(x) == length(y), length(x) &gt;= 3)\n  o &lt;- order(x); x &lt;- x[o]; y &lt;- y[o]\n\n  # first derivative at interior points (central difference)\n  d1  &lt;- (y[3:length(y)] - y[1:(length(y)-2)]) /\n         (x[3:length(x)] - x[1:(length(x)-2)])\n  x1  &lt;- x[2:(length(x)-1)]\n\n  # second derivative at interior points (difference of forward slopes)\n  slope &lt;- (y[-1] - y[-length(y)]) / (x[-1] - x[-length(x)])       # at midpoints\n  d2 &lt;- 2 / (x[3:length(x)] - x[1:(length(x)-2)]) *\n        (slope[2:length(slope)] - slope[1:(length(slope)-1)])\n  x2 &lt;- x[2:(length(x)-1)]\n\n  list(x = x, y = y, d1 = d1, x1 = x1, d2 = d2, x2 = x2)\n}\n\n# ---- zero crossing with linear interpolation ----\n.zero_cross &lt;- function(x, y, eps = 1e-10) {\n  s &lt;- sign(replace(y, abs(y) &lt; eps, 0))\n  i &lt;- which(s[-length(s)] * s[-1] &lt; 0)             # sign flip between i and i+1\n  if (!length(i)) return(numeric(0))\n  x[i] - y[i] * (x[i+1] - x[i]) / (y[i+1] - y[i])   # linear root between the pair\n}\n\n# ---- main finders ----\nfind_inflection &lt;- function(x, y, eps = 1e-10) {\n  fd &lt;- .fd(x, y)\n  xi &lt;- .zero_cross(fd$x2, fd$d2, eps)              # where y'' changes sign\n  tibble(x = xi, y = approx(fd$x, fd$y, xi)$y)\n}\n\nfind_turning &lt;- function(x, y, eps = 1e-10) {\n  fd &lt;- .fd(x, y)\n  xt &lt;- .zero_cross(fd$x1, fd$d1, eps)              # where y' changes sign\n  # classify with the sign of y'' at the same x (interpolated)\n  d2_at_xt &lt;- approx(fd$x2, fd$d2, xt)$y\n  tibble(x = xt, y = approx(fd$x, fd$y, xt)$y,\n         type = ifelse(d2_at_xt &lt; 0, \"max\", \"min\"))\n}\n\n\nLet’s try it\n\nfind_inflection(df$x, df$y)\n\n\n  \n\n\nfind_turning(df$x, df$y)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inflection point</span>"
    ]
  },
  {
    "objectID": "inflx.html#elbowknee-point",
    "href": "inflx.html#elbowknee-point",
    "title": "3  Inflection point",
    "section": "3.2 Elbow/knee point",
    "text": "3.2 Elbow/knee point\n\nWhat it is: Where the curve starts to flatten the most (the distance from the curve to the imaginary straight line between the first and final observation is the greatest)\nWhen to use it: For monotonic curves to spot the point where extra effort gives little added benefit. For example, to find a daily step goal above which the gains are not worth it (Ding et al., 2025)\n\nUse pathviewr::find_curve_elbow() to find the elbow. For comparison, we can also compute it manually by measuring the maximum distance from the curve to the straight line connecting the first and last observations.\n\nx &lt;- seq(0, 10, length.out = 300)\ny &lt;- 10 * (1 - exp(-1.1 * x))\ndf &lt;- tibble(x, y)\n\n# The imaginary straight line between the first and final observation\nx1 &lt;- df$x[1]\ny1 &lt;- df$y[1]\nx2 &lt;- df$x[nrow(df)]\ny2 &lt;- df$y[nrow(df)]\n\n# Find the distance\nden &lt;- sqrt((y2 - y1)^2 + (x2 - x1)^2)\ndist_to_chord &lt;- abs((y2 - y1)*df$x - (x2 - x1)*df$y + x2*y1 - y2*x1) / den\n\nour_idx &lt;- which.max(dist_to_chord)\nour_pt  &lt;- df[our_idx, ]\ncolnames(our_pt) &lt;- paste0(colnames(our_pt), \"_our\")\nour_d   &lt;- dist_to_chord[our_idx]\n\n# Elbow via pathviewr\npv_idx &lt;- pathviewr::find_curve_elbow(df, export_type = \"row_num\")\npv_pt  &lt;- df[pv_idx, ]\ncolnames(pv_pt) &lt;- paste0(colnames(pv_pt), \"_pv\")\n\ncbind(our_pt, pv_pt)\n\n\n  \n\n\n\nNow let’s visualise our elbow.\n\n## Foot of the perpendicular from the elbow to the chord\nproject_point_to_line &lt;- function(px, py, x1, y1, x2, y2) {\n  t &lt;- ((px - x1) * (x2 - x1) + (py - y1) * (y2 - y1)) / ((x2 - x1)^2 + (y2 - y1)^2)\n  tibble(x = x1 + t * (x2 - x1), y = y1 + t * (y2 - y1))\n}\nfoot &lt;- project_point_to_line(our_pt$x_our, our_pt$y_our, x1, y1, x2, y2)\nmid  &lt;- tibble(x = (our_pt$x_our + foot$x) / 2,\n               y = (our_pt$y_our + foot$y) / 2)\n\nymin &lt;- min(df$y) - 0.5\nymax &lt;- max(df$y) + 0.5\ny_star &lt;- our_pt$y_our\n\nshades &lt;- tibble::tibble(\n  xmin = -Inf, xmax =  Inf,\n  ymin = c(ymin, y_star),\n  ymax = c(y_star, ymax),\n  band = c(\"Below elbow\", \"Above elbow\")\n)\n\n## Plot\nggplot(df, aes(x, y)) +\n  # background shading (two horizontal bands)\n  geom_rect(\n    data = shades,\n    aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, fill = band),\n    alpha = 0.18, inherit.aes = FALSE\n  ) +\n  geom_line(linewidth = 1.2) +\n  # chord (end-to-end straight line)\n  annotate(\n    \"segment\",\n    x = x1,\n    y = y1,\n    xend = x2,\n    yend = y2,\n    linetype = \"dashed\",\n    colour = \"grey50\"\n  ) +\n  # our elbow + perpendicular\n  geom_point(\n    data = our_pt,\n    aes(x_our, y_our),\n    colour = \"blue\",\n    size = 3\n  ) +\n  annotate(\n    \"segment\",\n    x = our_pt$x_our,\n    y = our_pt$y_our,\n    xend = foot$x,\n    yend = foot$y,\n    colour = \"blue\"\n  ) +\n  scale_y_continuous(expand = c(0, 0)) +\n  scale_fill_bmj() +\n  coord_fixed(ratio = 1) +\n  theme_classic(base_size = 12) +\n  theme(legend.position = \"none\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inflection point</span>"
    ]
  },
  {
    "objectID": "inflx.html#breakpointthreshold",
    "href": "inflx.html#breakpointthreshold",
    "title": "3  Inflection point",
    "section": "3.3 Breakpoint/threshold",
    "text": "3.3 Breakpoint/threshold\n\nWhat it is: Where the relationship’s slope changes in a piecewise model\nWhen to use it: When you need an interpretable threshold with inference (estimate + CI) and potentially different effects below vs above the threshold. For example, tto find a biomarker level above which disease risk is higher (Chen et al., 2024)\nInterpretation: We estimate a change in slope at \\(x_0\\) = 3.4 (95% CI: 2.8-4.1). Below \\(x_0\\), each unit \\(x\\) increases \\(y\\) by \\(b_1\\); above \\(x_0\\), by \\(b_2\\)\n\nWe will simulating some data where the effect of \\(x\\) on the outcome \\(y\\) changes slope after a certain point (let choose that point \\(x_0 = 45\\) here).\n\nset.seed(123)\nn   &lt;- 2000\nx &lt;- pmin(rgamma(n, shape = 5, rate = 0.08), 250)  # skewed, realistic range\neta &lt;- -3 + 0.059 * pmin(x, 45) + 0.014 * pmax(x - 45, 0)\np   &lt;- plogis(eta)\ny  &lt;- rbinom(n, 1, p)\ndat &lt;- tibble(x, y)\n\nFirst, we check for non-linearity by fitting both a simple logistic model and a restricted cubic spline, and then compare them with a likelihood ratio test.\n\nm_lin &lt;- glm(y ~ x, family = binomial, data = dat)\nm_rcs &lt;- glm(y ~ rcs(x, 4), family = binomial, data = dat)\n\nanova(m_lin, m_rcs, test = \"LRT\")\n\n\n  \n\n\n\nFor convenience when computing the odds ratio, we will fit the model using rms::lrm().\n\ndd &lt;- datadist(dat)\noptions(datadist='dd')\nm_rcs2 &lt;- lrm(y ~ rcs(x, 4), data = dat)\n\n# Make sure that this model is the same as the model we fit with glm\nm_rcs\n\n\nCall:  glm(formula = y ~ rcs(x, 4), family = binomial, data = dat)\n\nCoefficients:\n (Intercept)    rcs(x, 4)x   rcs(x, 4)x'  rcs(x, 4)x''  \n    -2.76208       0.05324      -0.10983       0.27566  \n\nDegrees of Freedom: 1999 Total (i.e. Null);  1996 Residual\nNull Deviance:      2733 \nResidual Deviance: 2575     AIC: 2583\n\nm_rcs2\n\nLogistic Regression Model\n\nlrm(formula = y ~ rcs(x, 4), data = dat)\n\n                       Model Likelihood       Discrimination    Rank Discrim.    \n                             Ratio Test              Indexes          Indexes    \nObs          2000    LR chi2     158.48       R2       0.102    C       0.653    \n 0           1140    d.f.             3      R2(3,2000)0.075    Dxy     0.307    \n 1            860    Pr(&gt; chi2) &lt;0.0001    R2(3,1470.6)0.100    gamma   0.307    \nmax |deriv| 1e-06                             Brier    0.227    tau-a   0.151    \n\n          Coef    S.E.   Wald Z Pr(&gt;|Z|)\nIntercept -2.7621 0.3821 -7.23  &lt;0.0001 \nx          0.0532 0.0102  5.23  &lt;0.0001 \nx'        -0.1098 0.0394 -2.79  0.0053  \nx''        0.2757 0.1109  2.49  0.0129  \n\n\nLet’s visualise it.\n\npred &lt;- Predict(m_rcs2, x = seq(min(dat$x), max(dat$x), length.out = 1000), ref.zero = T, fun = exp, conf.int = 0.95)\n\nggplot() +\n  geom_line(data = pred, aes(x = x, y = yhat)) +\n  geom_ribbon(data = pred, aes(x = x, y = yhat, ymin = lower, ymax = upper), alpha = 0.3) +\n  scale_y_log10() +\n  labs(y = \"y\") +\n  theme_classic()\n\n\n\n\n\n\n\n\nNow to formally identify the breakpoint (sometimes referred to as an “inflection point”), we fit a segmented regression model using segmented::segmented() function on the logistic model.\n\nm_seg &lt;- segmented::segmented(m_lin, seg.Z = ~ x)\nsummary(m_seg)\n\n\n    ***Regression Model with Segmented Relationship(s)***\n\nCall: \nsegmented.glm(obj = m_lin, seg.Z = ~x)\n\nEstimated Break-Point(s):\n          Est. St.Err\npsi1.x 42.017   4.29\n\nCoefficients of the linear terms:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -3.01495    0.49340  -6.111 9.93e-10 ***\nx            0.05994    0.01467   4.085 4.41e-05 ***\nU1.x        -0.04432    0.01486  -2.984       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\nNull     deviance: 2733.3  on 1999  degrees of freedom\nResidual deviance: 2571.1  on 1996  degrees of freedom\nAIC: 2579.1\n\nBoot restarting based on 7 samples. Last fit:\nConvergence attained in 1 iterations (rel. change 1.2537e-09)\n\n\nThe breakpoint is estimated at 42.017. We can also get the confidence interval.\n\nconfint(m_seg, parm = \"x\", level = 0.95)\n\n          Est. CI(95%).low CI(95%).up\npsi1.x 42.0165     33.6024    50.4306\n\n\nLet’s have a look at the slopes.\n\nsegmented::slope(m_seg)\n\n$x\n           Est.   St.Err. t value CI(95%).l CI(95%).u\nslope1 0.059937 0.0146720  4.0850  0.031180  0.088695\nslope2 0.015613 0.0023258  6.7129  0.011054  0.020171\n\n\nTranslate the slopes into ORs.\n\nsl &lt;- data.frame(segmented::slope(m_seg)$x) |&gt; \n  janitor::clean_names()\n\n# (optional) grab the estimated breakpoint to label rows nicely\nbp &lt;- as.numeric(summary(m_seg)$psi[ , grep(\"^Est\", colnames(summary(m_seg)$psi), ignore.case = TRUE)[1]])\n\nsl |&gt;\n  rownames_to_column(\"segment\") |&gt;\n  mutate(\n    segment = if (nrow(sl) == 2)\n      c(paste0(\"x \\u2264 \", round(bp, 1)), paste0(\"x &gt; \", round(bp, 1)))\n      else segment,                           # works for &gt;1 breakpoints too\n    OR       = exp(est),\n    CI_low   = exp(ci_95_l),\n    CI_high  = exp(ci_95_u),\n    p.value  = 2 * pnorm(abs(t_value), lower.tail = FALSE)\n  ) |&gt; \n  dplyr::select(segment, OR, CI_low, CI_high, p.value)\n\n\n  \n\n\n\n\n\n\n\nChen, X., Lin, Z., Chen, Y., & Lin, C. (2024). C-reactive protein/lymphocyte ratio as a prognostic biomarker in acute pancreatitis: A cross-sectional study assessing disease severity. International Journal of Surgery, 110(6), 3223. https://doi.org/10.1097/JS9.0000000000001273\n\n\nDing, D., Nguyen, B., Nau, T., Luo, M., Cruz, B. del P., Dempsey, P. C., Munn, Z., Jefferis, B. J., Sherrington, C., Calleja, E. A., Chong, K. H., Davis, R., Francois, M. E., Tiedemann, A., Biddle, S. J. H., Okely, A., Bauman, A., Ekelund, U., Clare, P., & Owen, K. (2025). Daily steps and health outcomes in adults: A systematic review and dose-response meta-analysis. The Lancet Public Health, 10(8), e668–e681. https://doi.org/10.1016/S2468-2667(25)00164-1",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inflection point</span>"
    ]
  },
  {
    "objectID": "samplesize.html",
    "href": "samplesize.html",
    "title": "4  samplesize",
    "section": "",
    "text": "4.1 Estimate a population mean\nFor an i.i.d. sample \\(X_1, \\cdots, X_n\\) with population variance \\(\\sigma^2\\):\n\\[\n\\bar{X}=\\frac{1}{n} \\sum_{i=1}^n X_i \\quad \\text { has } \\quad \\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\sigma^2 / n\\right)\n\\]\nThe confidence interval is:\n\\[\n\\bar{X} \\pm z_{1-\\alpha / 2} \\frac{\\sigma}{\\sqrt{n}}\n\\]\nDenote the desired half-width (absolute precision) by \\(d\\), such that:\n\\[\nd = z_{1-\\alpha / 2} \\frac{\\sigma}{\\sqrt{n}}\n\\]\nAfter rearranging:\n\\[\nn=\\left(\\frac{z_{1-\\alpha / 2} \\sigma}{d}\\right)^2\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>samplesize</span>"
    ]
  },
  {
    "objectID": "cutoff.html",
    "href": "cutoff.html",
    "title": "Cut-off value",
    "section": "",
    "text": "ROC analysis\nBayesian approach",
    "crumbs": [
      "Cut-off value"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Chen, X., Lin, Z., Chen, Y., & Lin, C. (2024). C-reactive\nprotein/lymphocyte ratio as a prognostic biomarker in acute\npancreatitis: A cross-sectional study assessing disease severity.\nInternational Journal of Surgery, 110(6), 3223. https://doi.org/10.1097/JS9.0000000000001273\n\n\nDing, D., Nguyen, B., Nau, T., Luo, M., Cruz, B. del P., Dempsey, P. C.,\nMunn, Z., Jefferis, B. J., Sherrington, C., Calleja, E. A., Chong, K.\nH., Davis, R., Francois, M. E., Tiedemann, A., Biddle, S. J. H., Okely,\nA., Bauman, A., Ekelund, U., Clare, P., & Owen, K. (2025). Daily\nsteps and health outcomes in adults: A systematic review and\ndose-response meta-analysis. The Lancet Public Health,\n10(8), e668–e681. https://doi.org/10.1016/S2468-2667(25)00164-1",
    "crumbs": [
      "References"
    ]
  }
]